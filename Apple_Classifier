import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix
import yfinance as yf


ticker = yf.Ticker("AAPL")
data = ticker.history(period="1d", start="2010-01-01", end="2023-07-09")

# Extrair apenas a coluna "Close" (preço de fechamento)
df = data[['Close']]
df['Close'].plot(figsize=(15,5))

data['Close_Difference'] = data['Close'].diff()
data['Class'] = np.where(data['Close_Difference'] > 0, 1, 0)
data.dropna(inplace=True)

X = data[['Open', 'High', 'Low', 'Close', 'Volume']]
y = data['Class']

from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Separar 80% dos dados para treinamento e 20% para teste
X_train_temp, X_test, y_train_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=200)

# Separar 75% dos dados de treinamento para treinamento final e 25% para validação
X_train, X_val, y_train, y_val = train_test_split(X_train_temp, y_train_temp, test_size=0.25, random_state=200)

# Imprimir as proporções dos conjuntos de treinamento, validação e teste
print("Treinamento:", len(X_train), "amostras -", len(X_train)/len(X)*100, "%")
print("Validação:", len(X_val), "amostras -", len(X_val)/len(X)*100, "%")
print("Teste:", len(X_test), "amostras -", len(X_test)/len(X)*100, "%")

import matplotlib.pyplot as plt

# Plotar um gráfico mostrando a separação dos grupos
plt.figure(figsize=(8, 6))
plt.scatter(X_train['Close'], X_train['High'], c='blue', label='Treinamento')
plt.scatter(X_val['Close'], X_val['High'], c='green', label='Validação')
plt.scatter(X_test['Close'], X_test['High'], c='red', label='Teste')
plt.xlabel('Close')
plt.ylabel('High')
plt.legend()
plt.title(' Separação dos Grupos mais de 1 variável')
plt.ylim(0, 200)
plt.show()

import matplotlib.pyplot as plt

# Plotar um gráfico mostrando a separação dos grupos
plt.figure(figsize=(8, 6))
plt.scatter(X_train['Close'], X_train['Close'], c='blue', label='Treinamento')
plt.scatter(X_val['Close'], X_val['Close'], c='green', label='Validação')
plt.scatter(X_test['Close'], X_test['Close'], c='red', label='Teste')
plt.xlabel('Close')
plt.ylabel('Close')
plt.legend()
plt.title('Separação dos Grupos com apenas dados de fechamento')
plt.ylim(0, 200)
plt.show()

from imblearn.over_sampling import RandomOverSampler

# Manter apenas a coluna 'Close' no conjunto de dados
X = data[['Close']]
y = data['Class']

# Separar 80% dos dados para treinamento e 20% para teste
X_train_temp, X_test, y_train_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=200)

# Separar 75% dos dados de treinamento para treinamento final e 25% para validação
X_train, X_val, y_train, y_val = train_test_split(X_train_temp, y_train_temp, test_size=0.25, random_state=200)

# Aplicar oversampling na classe minoritária apenas no conjunto de treinamento
oversampler = RandomOverSampler(random_state=200)
X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)

# Regressão Logística com dados balanceados
logistic_model = LogisticRegression()
logistic_model.fit(X_train_resampled, y_train_resampled)
logistic_predictions = logistic_model.predict(X_test)
logistic_classification_report = classification_report(y_test, logistic_predictions, zero_division=0, labels=np.unique(y_test))
print("Logistic Regression Classification Report:")
print(logistic_classification_report)

# Árvore de Decisão
decision_tree_model = DecisionTreeClassifier()
decision_tree_model.fit(X_train, y_train)
decision_tree_predictions = decision_tree_model.predict(X_test)
decision_tree_classification_report = classification_report(y_test, decision_tree_predictions, zero_division=0, labels=np.unique(y_test))
print("Decision Tree Classification Report:")
print(decision_tree_classification_report)

# Random Forest
random_forest_model = RandomForestClassifier()
random_forest_model.fit(X_train, y_train)
random_forest_predictions = random_forest_model.predict(X_test)
random_forest_classification_report = classification_report(y_test, random_forest_predictions, zero_division=0, labels=np.unique(y_test))
print("Random Forest Classification Report:")
print(random_forest_classification_report)

# SVM com balanceamento de classes
svm_model = SVC(class_weight='balanced')
svm_model.fit(X_train, y_train)
svm_predictions = svm_model.predict(X_test)
svm_classification_report = classification_report(y_test, svm_predictions, zero_division=0, labels=np.unique(y_test))
print("SVM Classification Report:")
print(svm_classification_report)

import seaborn as sns
# Matriz de confusão para Regressão Logística
logistic_confusion_matrix = confusion_matrix(y_test, logistic_predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(logistic_confusion_matrix, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix - Logistic Regression")
plt.xlabel("Predicted Class")
plt.ylabel("True Class")
plt.show()

# Matriz de confusão para Árvore de Decisão
decision_tree_confusion_matrix = confusion_matrix(y_test, decision_tree_predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(decision_tree_confusion_matrix, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix - Decision Tree")
plt.xlabel("Predicted Class")
plt.ylabel("True Class")
plt.show()

# Matriz de confusão para Random Forest
random_forest_confusion_matrix = confusion_matrix(y_test, random_forest_predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(random_forest_confusion_matrix, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix - Random Forest")
plt.xlabel("Predicted Class")
plt.ylabel("True Class")
plt.show()

# Matriz de confusão para SVM
svm_confusion_matrix = confusion_matrix(y_test, svm_predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(svm_confusion_matrix, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix - SVM")
plt.xlabel("Predicted Class")
plt.ylabel("True Class")
plt.show()

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

# Regressão Logística
logistic_model = LogisticRegression()
logistic_model.fit(X_train, y_train)
logistic_probabilities = logistic_model.predict_proba(X_test)[:, 1]
logistic_fpr, logistic_tpr, _ = roc_curve(y_test, logistic_probabilities)
logistic_auc = auc(logistic_fpr, logistic_tpr)
plt.plot(logistic_fpr, logistic_tpr, label='Logistic Regression (AUC = {:.2f})'.format(logistic_auc))

# Árvore de Decisão
decision_tree_model = DecisionTreeClassifier()
decision_tree_model.fit(X_train, y_train)
decision_tree_probabilities = decision_tree_model.predict_proba(X_test)[:, 1]
decision_tree_fpr, decision_tree_tpr, _ = roc_curve(y_test, decision_tree_probabilities)
decision_tree_auc = auc(decision_tree_fpr, decision_tree_tpr)
plt.plot(decision_tree_fpr, decision_tree_tpr, label='Decision Tree (AUC = {:.2f})'.format(decision_tree_auc))

# Random Forest
random_forest_model = RandomForestClassifier()
random_forest_model.fit(X_train, y_train)
random_forest_probabilities = random_forest_model.predict_proba(X_test)[:, 1]
random_forest_fpr, random_forest_tpr, _ = roc_curve(y_test, random_forest_probabilities)
random_forest_auc = auc(random_forest_fpr, random_forest_tpr)
plt.plot(random_forest_fpr, random_forest_tpr, label='Random Forest (AUC = {:.2f})'.format(random_forest_auc))

# SVM
svm_model = SVC(probability=True)
svm_model.fit(X_train, y_train)
svm_probabilities = svm_model.predict_proba(X_test)[:, 1]
svm_fpr, svm_tpr, _ = roc_curve(y_test, svm_probabilities)
svm_auc = auc(svm_fpr, svm_tpr)
plt.plot(svm_fpr, svm_tpr, label='SVM (AUC = {:.2f})'.format(svm_auc))

plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc='lower right')
plt.show()

from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error
import numpy as np
import matplotlib.pyplot as plt

# Definir o número de folds desejado
n_folds = 5

# Criar uma instância de KFold
kfold = KFold(n_splits=n_folds, shuffle=True, random_state=200)

# Lista para armazenar os resultados de cada modelo
model_scores = []

# Iterar pelos modelos
for model_name, model in zip(["Logistic Regression", "Decision Tree", "Random Forest", "SVM"],
                             [logistic_model, decision_tree_model, random_forest_model, svm_model]):

    # Lista para armazenar os scores dos folds
    model_fold_scores = []

    # Iterar pelos folds
    for fold, (train_index, val_index) in enumerate(kfold.split(X_train)):

        # Dividir os dados em treinamento e validação para o fold atual
        X_fold_train, X_fold_val = X_train.iloc[train_index], X_train.iloc[val_index]
        y_fold_train, y_fold_val = y_train.iloc[train_index], y_train.iloc[val_index]

        # Treinar o modelo no conjunto de treinamento do fold atual
        model.fit(X_fold_train, y_fold_train)

        # Avaliar o modelo no conjunto de validação do fold atual
        fold_score = model.score(X_fold_val, y_fold_val)
        model_fold_scores.append(fold_score)

    # Calcular a média dos scores dos folds para o modelo atual
    mean_score = np.mean(model_fold_scores)
    model_scores.append(mean_score)

# Visualizações (Gráficos)
plt.figure(figsize=(10, 6))
plt.bar(["Logistic Regression", "Decision Tree", "Random Forest", "SVM"], model_scores)
plt.xlabel("Model")
plt.ylabel("Mean CV Score")
plt.title("Cross-Validation Scores for Different Models")
plt.show()

# ...

# Calcular o MSE para cada modelo
logistic_mse = mean_squared_error(y_test, logistic_predictions)
decision_tree_mse = mean_squared_error(y_test, decision_tree_predictions)
random_forest_mse = mean_squared_error(y_test, random_forest_predictions)
svm_mse = mean_squared_error(y_test, svm_predictions)

# Tabulação de Resultados
results = {
    "Model": ["Logistic Regression", "Decision Tree", "Random Forest", "SVM"],
    "Mean CV Score": model_scores,
    "Classification Report": [logistic_classification_report, decision_tree_classification_report, random_forest_classification_report, svm_classification_report],
    "Mean Squared Error": [logistic_mse, decision_tree_mse, random_forest_mse, svm_mse]
}

# Exibição dos resultados em uma tabela
results_table = pd.DataFrame(results)

# Exibição da tabela
print(results_table)

import matplotlib.pyplot as plt
from sklearn.neural_network import MLPClassifier

# Criar uma instância do MLP Classifier com as configurações desejadas
mlp_model = MLPClassifier(hidden_layer_sizes=(100,), random_state=200)

# Ajustar o modelo aos dados de treinamento
mlp_model.fit(X_train, y_train)

# Obter as camadas ocultas e o número de neurônios em cada camada
hidden_layer_sizes = mlp_model.hidden_layer_sizes
n_neurons = [X_train.shape[1]] + list(hidden_layer_sizes) + [mlp_model.n_outputs_]

# Plotar o diagrama da rede neural
plt.figure(figsize=(8, 6))
plt.title("Estrutura da Rede Neural")
for i in range(len(n_neurons) - 1):
    plt.scatter([i + 1] * n_neurons[i], range(n_neurons[i]), color='blue', label="Camada de Entrada" if i == 0 else None)
    plt.scatter([i + 2] * n_neurons[i + 1], range(n_neurons[i + 1]), color='red', label="Camada Oculta" if i < len(n_neurons) - 2 else "Camada de Saída")
    for j in range(n_neurons[i]):
        for k in range(n_neurons[i + 1]):
            plt.plot([i + 1, i + 2], [j, k], color='black')
plt.xlabel("Camadas")
plt.ylabel("Neurônios")
plt.legend()
plt.show()

from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import KFold, cross_val_score
from sklearn.metrics import classification_report, mean_squared_error
import numpy as np
import matplotlib.pyplot as plt

# Criação e treinamento do MLPClassifier
mlp_model = MLPClassifier(hidden_layer_sizes=(100,), random_state=200)
mlp_model.fit(X_train, y_train)

# Previsões com o MLPClassifier
mlp_predictions = mlp_model.predict(X_test)

# Relatório de classificação do MLPClassifier
mlp_classification_report = classification_report(y_test, mlp_predictions, zero_division=0, labels=np.unique(y_test))
print("MLP Classifier Classification Report:")
print(mlp_classification_report)

# Avaliação do MLPClassifier com validação cruzada K-fold
n_folds = 5
kfold = KFold(n_splits=n_folds, shuffle=True, random_state=200)
mlp_scores = cross_val_score(mlp_model, X_train, y_train, cv=kfold)

# Lista para armazenar os resultados de cada modelo
model_scores = []

# Iterar pelos modelos
for model_name, model in zip(["Logistic Regression", "Decision Tree", "Random Forest", "SVM", "MLP Classifier"],
                             [logistic_model, decision_tree_model, random_forest_model, svm_model, mlp_model]):

    # Lista para armazenar os scores dos folds
    model_fold_scores = []

    # Iterar pelos folds
    for fold, (train_index, val_index) in enumerate(kfold.split(X_train)):
        # Dividir os dados em treinamento e validação para o fold atual
        X_fold_train, X_fold_val = X_train.iloc[train_index], X_train.iloc[val_index]
        y_fold_train, y_fold_val = y_train.iloc[train_index], y_train.iloc[val_index]

        # Treinar o modelo no conjunto de treinamento do fold atual
        model.fit(X_fold_train, y_fold_train)

        # Avaliar o modelo no conjunto de validação do fold atual
        fold_score = model.score(X_fold_val, y_fold_val)
        model_fold_scores.append(fold_score)

    # Calcular a média dos scores dos folds para o modelo atual
    mean_score = np.mean(model_fold_scores)
    model_scores.append(mean_score)

# Calcular o MSE para cada modelo
logistic_mse = mean_squared_error(y_test, logistic_predictions)
decision_tree_mse = mean_squared_error(y_test, decision_tree_predictions)
random_forest_mse = mean_squared_error(y_test, random_forest_predictions)
svm_mse = mean_squared_error(y_test, svm_predictions)
mlp_mse = mean_squared_error(y_test, mlp_predictions)

# Tabulação dos resultados
results = {
    "Model": ["Logistic Regression", "Decision Tree", "Random Forest", "SVM", "MLP Classifier"],
    "Mean CV Score": model_scores,
    "Classification Report": [logistic_classification_report, decision_tree_classification_report, random_forest_classification_report, svm_classification_report, mlp_classification_report],
    "Mean Squared Error": [logistic_mse, decision_tree_mse, random_forest_mse, svm_mse, mlp_mse]
}

results_table = pd.DataFrame(results)

# Visualização (Gráfico)
plt.figure(figsize=(10, 6))
plt.bar(results_table["Model"], results_table["Mean CV Score"])
plt.xlabel("Model")
plt.ylabel("Mean CV Score")
plt.title("Cross-Validation Scores for Different Models")
plt.show()

# Exibição dos Resultados
print(results_table)

from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import KFold, cross_val_score
from sklearn.metrics import classification_report, mean_squared_error
from imblearn.over_sampling import RandomOverSampler
import numpy as np
import matplotlib.pyplot as plt
from imblearn.over_sampling import SMOTE

from imblearn.under_sampling import NearMiss

# Aplicar undersampling
undersampler = NearMiss()
X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)

# Treinar o modelo MLPClassifier com os dados balanceados
mlp_model = MLPClassifier(hidden_layer_sizes=(100,), random_state=200)
mlp_model.fit(X_train_resampled, y_train_resampled)

# Fazer previsões com o MLPClassifier
mlp_predictions = mlp_model.predict(X_test)

# Relatório de classificação do MLPClassifier
mlp_classification_report = classification_report(y_test, mlp_predictions, zero_division=0, labels=np.unique(y_test))
print("MLP Classifier Classification Report:")
print(mlp_classification_report)


# Avaliação do MLPClassifier com validação cruzada K-fold
n_folds = 5
kfold = KFold(n_splits=n_folds, shuffle=True, random_state=200)
mlp_scores = cross_val_score(mlp_model, X_train_resampled, y_train_resampled, cv=kfold)

# Lista para armazenar os resultados de cada modelo
model_scores = []

# Iterar pelos modelos
for model_name, model in zip(["Logistic Regression", "Decision Tree", "Random Forest", "SVM", "MLP Classifier"],
                             [logistic_model, decision_tree_model, random_forest_model, svm_model, mlp_model]):

    # Lista para armazenar os scores dos folds
    model_fold_scores = []

    # Iterar pelos folds
    for fold, (train_index, val_index) in enumerate(kfold.split(X_train_resampled)):
        # Dividir os dados em treinamento e validação para o fold atual
        X_fold_train, X_fold_val = X_train_resampled.iloc[train_index], X_train_resampled.iloc[val_index]
        y_fold_train, y_fold_val = y_train_resampled.iloc[train_index], y_train_resampled.iloc[val_index]

        # Treinar o modelo no conjunto de treinamento do fold atual
        model.fit(X_fold_train, y_fold_train)

        # Avaliar o modelo no conjunto de validação do fold atual
        fold_score = model.score(X_fold_val, y_fold_val)
        model_fold_scores.append(fold_score)

    # Calcular a média dos scores dos folds para o modelo atual
    mean_score = np.mean(model_fold_scores)
    model_scores.append(mean_score)

# Calcular o MSE para cada modelo
logistic_mse = mean_squared_error(y_test, logistic_predictions)
decision_tree_mse = mean_squared_error(y_test, decision_tree_predictions)
random_forest_mse = mean_squared_error(y_test, random_forest_predictions)
svm_mse = mean_squared_error(y_test, svm_predictions)
mlp_mse = mean_squared_error(y_test, mlp_predictions)

# Tabulação dos resultados
results = {
    "Model": ["Logistic Regression", "Decision Tree", "Random Forest", "SVM", "MLP Classifier"],
    "Mean CV Score": model_scores,
    "Classification Report": [logistic_classification_report, decision_tree_classification_report, random_forest_classification_report, svm_classification_report, mlp_classification_report],
    "Mean Squared Error": [logistic_mse, decision_tree_mse, random_forest_mse, svm_mse, mlp_mse]
}

results_table = pd.DataFrame(results)

# Visualização (Gráfico)
plt.figure(figsize=(10, 6))
plt.bar(results_table["Model"], results_table["Mean CV Score"])
plt.xlabel("Model")
plt.ylabel("Mean CV Score")
plt.title("Cross-Validation Scores for Different Models")
plt.show()

# Exibição dos Resultados
print(results_table)

from sklearn.metrics import roc_curve, auc

# Calcular as probabilidades de pertencer à classe positiva
mlp_probabilities = mlp_model.predict_proba(X_test)[:, 1]

# Calcular a taxa de falso positivo, a taxa de verdadeiro positivo e o limiar
fpr, tpr, thresholds = roc_curve(y_test, mlp_probabilities)

# Calcular a área sob a curva ROC
roc_auc = auc(fpr, tpr)

# Plotar a curva ROC
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label='MLP Classifier (AUC = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('Taxa de Falso Positivo')
plt.ylabel('Taxa de Verdadeiro Positivo')
plt.title('Curva ROC - MLP Classifier')
plt.legend(loc='lower right')
plt.show()






